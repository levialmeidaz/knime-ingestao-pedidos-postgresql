
# ðŸ“¦ Pipeline de IngestÃ£o de Pedidos com KNIME + PostgreSQL

Este projeto automatiza a ingestÃ£o de arquivos `.csv` contendo pedidos comerciais, utilizando **KNIME Analytics Platform** para tratamento dos dados e **PostgreSQL** como banco relacional de destino.

---

## ðŸš€ Funcionalidades

- ðŸ“ Leitura automÃ¡tica de mÃºltiplos arquivos `.csv`
- ðŸ”„ Loop com validaÃ§Ã£o de estrutura de dados
- ðŸ§¼ CriaÃ§Ã£o de chave Ãºnica (`chave_pedido`)
- ðŸ§¹ DeduplicaÃ§Ã£o com base na Ãºltima ocorrÃªncia
- ðŸ“¤ Upsert (inserÃ§Ã£o/atualizaÃ§Ã£o) no PostgreSQL via `DB Merge`
  
---

## ðŸ“‚ Estrutura do Projeto

```
knime-pipeline-pedidos/
â”œâ”€â”€ fluxo_csv_pedidos.knwf        # Workflow completo no KNIME
â”œâ”€â”€ arquivos_exemplo/             # CSVs fictÃ­cios para testes
â”‚   â”œâ”€â”€ pedidos_ficticio_01.csv
â”‚   â”œâ”€â”€ pedidos_ficticio_02.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ screenshots/                  # Prints do fluxo e tabelas
â””â”€â”€ README.md                     # DescriÃ§Ã£o do projeto
```

---

## ðŸ§ª Tecnologias Utilizadas

- [KNIME Analytics Platform](https://www.knime.com/)
- PostgreSQL
- Faker (para gerar dados fictÃ­cios)
- Python (para prÃ©-processamento e anonimizaÃ§Ã£o)

---


## ðŸ“ Como Executar

1. Baixe e instale o [KNIME](https://www.knime.com/downloads)
2. Importe o arquivo `.knwf` (`File > Import KNIME Workflow`)
3. Altere o caminho dos arquivos CSV para a pasta `arquivos_exemplo/`
4. Rode o fluxo completo

---

## ðŸ“Œ ObservaÃ§Ãµes

- Os dados utilizados sÃ£o **100% fictÃ­cios**, criados com a biblioteca `Faker`.

---

## ðŸ“¸ Prints do Projeto

![Fluxo KNIME](screenshots/knime_fluxo.png)

---
Desenvolvido com ðŸ’¡ por Levi Almeida
